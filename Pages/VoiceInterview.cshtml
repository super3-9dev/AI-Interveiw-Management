@page
@model InterviewBot.Pages.VoiceInterviewModel
@using Microsoft.AspNetCore.Mvc.Localization
@inject IViewLocalizer Localizer
@{
    ViewData["Title"] = Localizer["Voice Interview"];
    var currentCulture = HttpContext.Request.Query["culture"].ToString();
    if (string.IsNullOrEmpty(currentCulture))
    {
        currentCulture = HttpContext.Request.Cookies["culture"] ?? "en";
    }
}

<div class="voice-interview-container">
    <!-- Interview Header -->
    <div class="interview-header">
        <div class="header-content">
            <div class="interview-info">
                <h1 class="interview-title">
                    <i class="bi bi-mic"></i>
                    @Model.InterviewTopic
                </h1>
                <p class="interview-subtitle">AI-powered voice interview with real-time feedback</p>
            </div>
            <div class="interview-status">
                <span class="status-badge status-active">In Progress</span>
            </div>
        </div>
    </div>

    <!-- Voice Chat Area -->
    <div class="voice-chat-container">
        <div class="voice-messages" id="voiceMessages">
            <!-- AI Welcome Message -->
            <div class="voice-message ai-voice-message">
                <div class="voice-avatar">
                    <i class="bi bi-robot"></i>
                </div>
                <div class="voice-content">
                    <div class="voice-header">
                        <span class="voice-sender">AI</span>
                        <span class="voice-time" id="currentTime"></span>
                    </div>
                    <div class="voice-text">
                        Hello! I'm your AI career coach. We're going to have a practice interview. Let's start with the
                        first question: @Model.CurrentQuestion
                    </div>
                    <div class="voice-controls">
                        <button class="btn btn-sm btn-outline-primary" onclick="playAIResponse(this)">
                            <i class="bi bi-play-circle"></i> Play
                        </button>
                        <button class="btn btn-sm btn-outline-secondary" onclick="pauseAIResponse(this)">
                            <i class="bi bi-pause-circle"></i> Pause
                        </button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Voice Input Area -->
    <div class="voice-input-container">
        <div class="voice-input-wrapper">
            <div class="voice-control-panel">
                <button class="voice-record-btn" id="recordButton" onclick="toggleRecording()">
                    <i class="bi bi-mic-fill"></i>
                    <span class="record-text">Start Recording</span>
                </button>
                <div class="recording-indicator" id="recordingIndicator" style="display: none;">
                    <div class="pulse-dot"></div>
                    <span>Recording...</span>
                </div>
            </div>

            <div class="voice-transcription">
                <textarea id="transcriptionArea" class="transcription-textarea"
                    placeholder="Your voice will be transcribed here..." readonly></textarea>
                <div class="transcription-actions">
                    <button class="btn btn-primary" id="sendVoiceBtn" onclick="sendVoiceMessage()" disabled>
                        <i class="bi bi-send"></i> Send
                    </button>
                    <button class="btn btn-outline-secondary" onclick="clearTranscription()">
                        <i class="bi bi-trash"></i> Clear
                    </button>
                </div>
            </div>
        </div>
    </div>

    <!-- Action Buttons -->
    <div class="action-buttons">
        <a href="/Dashboard@(!string.IsNullOrEmpty(currentCulture) ? $"?culture={currentCulture}" : "")"
            class="btn btn-outline-secondary action-btn">
            <i class="bi bi-arrow-left"></i>
            Back to Dashboard
        </a>
        <button class="btn btn-danger action-btn" onclick="finishInterview()">
            <i class="bi bi-arrow-left"></i>
            Finish Interview
        </button>
    </div>
</div>

<style>
    .voice-interview-container {
        display: flex;
        flex-direction: column;
        height: 100vh;
        background-color: #f8f9fa;
    }

    /* Interview Header */
    .interview-header {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
        padding: 1.5rem 2rem;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    }

    .header-content {
        display: flex;
        justify-content: space-between;
        align-items: center;
        max-width: 1200px;
        margin: 0 auto;
    }

    .interview-info h1 {
        margin: 0;
        font-size: 1.75rem;
        font-weight: 600;
        display: flex;
        align-items: center;
        gap: 0.75rem;
    }

    .interview-subtitle {
        margin: 0.5rem 0 0 0;
        opacity: 0.9;
        font-size: 1rem;
    }

    .status-badge {
        padding: 0.5rem 1rem;
        border-radius: 2rem;
        font-size: 0.875rem;
        font-weight: 500;
    }

    .status-active {
        background-color: rgba(34, 197, 94, 0.2);
        color: #22c55e;
        border: 1px solid rgba(34, 197, 94, 0.3);
    }

    /* Voice Chat Container */
    .voice-chat-container {
        flex: 1;
        overflow-y: auto;
        padding: 2rem;
        max-width: 1200px;
        margin: 0 auto;
        width: 100%;
    }

    .voice-messages {
        display: flex;
        flex-direction: column;
        gap: 1.5rem;
    }

    /* Voice Message Styles */
    .voice-message {
        display: flex;
        gap: 1rem;
        max-width: 80%;
    }

    .ai-voice-message {
        align-self: flex-start;
    }

    .user-voice-message {
        align-self: flex-end;
        flex-direction: row-reverse;
    }

    .voice-avatar {
        width: 40px;
        height: 40px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        flex-shrink: 0;
    }

    .ai-voice-message .voice-avatar {
        background-color: #10b981;
        color: white;
    }

    .user-voice-message .voice-avatar {
        background-color: #3b82f6;
        color: white;
    }

    .voice-avatar i {
        font-size: 1.2rem;
    }

    .voice-content {
        background-color: white;
        padding: 1rem 1.5rem;
        border-radius: 1rem;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        position: relative;
        min-width: 300px;
    }

    .ai-voice-message .voice-content {
        border-bottom-left-radius: 0.25rem;
    }

    .user-voice-message .voice-content {
        border-bottom-right-radius: 0.25rem;
        background-color: #3b82f6;
        color: white;
    }

    .voice-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 0.5rem;
        font-size: 0.875rem;
        opacity: 0.8;
    }

    .voice-sender {
        font-weight: 600;
    }

    .voice-time {
        font-size: 0.75rem;
    }

    .voice-text {
        line-height: 1.6;
        margin-bottom: 1rem;
    }

    .voice-controls {
        display: flex;
        gap: 0.5rem;
        flex-wrap: wrap;
    }

    .voice-controls .btn {
        font-size: 0.8rem;
        padding: 0.25rem 0.5rem;
    }

    /* Voice Input Container */
    .voice-input-container {
        padding: 1.5rem 2rem;
        background-color: white;
        border-top: 1px solid #e9ecef;
    }

    .voice-input-wrapper {
        max-width: 1200px;
        margin: 0 auto;
        display: flex;
        flex-direction: column;
        gap: 1.5rem;
    }

    .voice-control-panel {
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 2rem;
    }

    .voice-record-btn {
        width: 80px;
        height: 80px;
        border-radius: 50%;
        background-color: #10b981;
        color: white;
        border: none;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        transition: all 0.3s ease;
        font-size: 1.5rem;
        gap: 0.25rem;
    }

    .voice-record-btn:hover {
        background-color: #059669;
        transform: scale(1.05);
    }

    .voice-record-btn.recording {
        background-color: #ef4444;
        animation: pulse 1.5s infinite;
    }

    .voice-record-btn.recording:hover {
        background-color: #dc2626;
    }

    .record-text {
        font-size: 0.75rem;
        font-weight: 500;
    }

    .recording-indicator {
        display: flex;
        align-items: center;
        gap: 0.5rem;
        color: #ef4444;
        font-weight: 500;
    }

    .pulse-dot {
        width: 12px;
        height: 12px;
        background-color: #ef4444;
        border-radius: 50%;
        animation: pulse 1.5s infinite;
    }

    .voice-transcription {
        display: flex;
        flex-direction: column;
        gap: 1rem;
    }

    .transcription-textarea {
        width: 100%;
        min-height: 100px;
        padding: 1rem;
        border: 2px solid #e9ecef;
        border-radius: 0.75rem;
        font-size: 1rem;
        line-height: 1.5;
        resize: vertical;
        transition: border-color 0.2s ease;
        outline: none;
    }

    .transcription-textarea:focus {
        border-color: #10b981;
    }

    .transcription-actions {
        display: flex;
        justify-content: center;
        gap: 1rem;
    }

    /* Action Buttons */
    .action-buttons {
        padding: 1.5rem 2rem;
        background-color: white;
        border-top: 1px solid #e9ecef;
        display: flex;
        justify-content: center;
        gap: 1rem;
        flex-wrap: wrap;
    }

    .action-btn {
        padding: 0.75rem 1.5rem;
        border-radius: 0.5rem;
        font-weight: 500;
        display: flex;
        align-items: center;
        gap: 0.5rem;
        transition: all 0.2s ease;
    }

    .action-btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
    }

    /* Loading Spinner */
    .spin {
        animation: spin 1s linear infinite;
    }

    @@keyframes pulse {

        0%,
        100% {
            opacity: 1;
        }

        50% {
            opacity: 0.5;
        }
    }

    @@keyframes spin {
        from {
            transform: rotate(0deg);
        }

        to {
            transform: rotate(360deg);
        }
    }

    /* Responsive Design */
    @@media (max-width: 768px) {
        .header-content {
            flex-direction: column;
            gap: 1rem;
            text-align: center;
        }

        .voice-chat-container {
            padding: 1rem;
        }

        .voice-message {
            max-width: 95%;
        }

        .voice-control-panel {
            flex-direction: column;
            gap: 1rem;
        }

        .voice-record-btn {
            width: 70px;
            height: 70px;
        }

        .action-buttons {
            flex-direction: column;
            align-items: center;
        }

        .action-btn {
            width: 100%;
            max-width: 300px;
            justify-content: center;
        }
    }

    @@media (max-width: 480px) {
        .interview-header {
            padding: 1rem;
        }

        .interview-info h1 {
            font-size: 1.5rem;
        }

        .voice-chat-container {
            padding: 0.5rem;
        }

        .voice-input-container {
            padding: 1rem;
        }

        .action-buttons {
            padding: 1rem;
        }
    }
</style>

<script>
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let currentAudio = null;

    // Initialize current time
    document.addEventListener('DOMContentLoaded', function () {
        updateCurrentTime();
        setInterval(updateCurrentTime, 1000);

        // Request microphone permission
        requestMicrophonePermission();
    });

    function updateCurrentTime() {
        const now = new Date();
        const timeString = now.toLocaleTimeString();
        document.getElementById('currentTime').textContent = timeString;
    }

    async function requestMicrophonePermission() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop()); // Stop the stream after permission
            console.log('Microphone permission granted');
        } catch (error) {
            console.error('Microphone permission denied:', error);
            alert('Microphone permission is required for voice interviews. Please allow microphone access and refresh the page.');
        }
    }

    async function toggleRecording() {
        if (!isRecording) {
            await startRecording();
        } else {
            stopRecording();
        }
    }

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];

            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                await processAudioRecording(audioBlob);
            };

            mediaRecorder.start();
            isRecording = true;

            // Update UI
            document.getElementById('recordButton').classList.add('recording');
            document.getElementById('recordButton').innerHTML = '<i class="bi bi-stop-fill"></i><span class="record-text">Stop</span>';
            document.getElementById('recordingIndicator').style.display = 'flex';

        } catch (error) {
            console.error('Error starting recording:', error);
            alert('Error starting recording. Please check your microphone permissions.');
        }
    }

    function stopRecording() {
        if (mediaRecorder && isRecording) {
            mediaRecorder.stop();
            mediaRecorder.stream.getTracks().forEach(track => track.stop());
            isRecording = false;

            // Update UI
            document.getElementById('recordButton').classList.remove('recording');
            document.getElementById('recordButton').innerHTML = '<i class="bi bi-mic-fill"></i><span class="record-text">Start Recording</span>';
            document.getElementById('recordingIndicator').style.display = 'none';
        }
    }

    async function processAudioRecording(audioBlob) {
        try {
            // For now, we'll simulate transcription
            // In real implementation, this would call OpenAI Whisper API
            const mockTranscription = "This is a simulated transcription of your voice recording. In a real implementation, this would be generated by OpenAI's Whisper API.";

            // Display transcription
            document.getElementById('transcriptionArea').value = mockTranscription;
            document.getElementById('sendVoiceBtn').disabled = false;

        } catch (error) {
            console.error('Error processing audio:', error);
            alert('Error transcribing audio. Please try again.');
        }
    }

    function sendVoiceMessage() {
        const transcription = document.getElementById('transcriptionArea').value.trim();

        if (!transcription) return;

        // Add user voice message to chat
        addUserVoiceMessage(transcription);

        // Clear transcription
        clearTranscription();

        // Generate AI voice response (in real implementation, this would use OpenAI)
        setTimeout(() => {
            generateAIVoiceResponse(transcription);
        }, 1000);
    }

    function addUserVoiceMessage(text) {
        const voiceMessages = document.getElementById('voiceMessages');
        const messageDiv = document.createElement('div');
        messageDiv.className = 'voice-message user-voice-message';

        const now = new Date();
        const timeString = now.toLocaleTimeString();

        messageDiv.innerHTML = `
            <div class="voice-avatar">
                <i class="bi bi-person"></i>
            </div>
            <div class="voice-content">
                <div class="voice-header">
                    <span class="voice-sender">You</span>
                    <span class="voice-time">${timeString}</span>
                </div>
                <div class="voice-text">${text}</div>
            </div>
        `;

        voiceMessages.appendChild(messageDiv);
        scrollToBottom();
    }

    async function generateAIVoiceResponse(userMessage) {
        const voiceMessages = document.getElementById('voiceMessages');
        const messageDiv = document.createElement('div');
        messageDiv.className = 'voice-message ai-voice-message';

        const now = new Date();
        const timeString = now.toLocaleTimeString();

        // Show loading state
        messageDiv.innerHTML = `
            <div class="voice-avatar">
                <i class="bi bi-robot"></i>
            </div>
            <div class="voice-content">
                <div class="voice-header">
                    <span class="voice-sender">AI</span>
                    <span class="voice-time">${timeString}</span>
                </div>
                <div class="voice-text">
                    <i class="bi bi-arrow-clockwise spin"></i> Thinking...
                </div>
                <div class="voice-controls">
                    <button class="btn btn-sm btn-outline-primary" onclick="playAIResponse(this)" disabled>
                        <i class="bi bi-play-circle"></i> Play
                    </button>
                    <button class="btn btn-sm btn-outline-secondary" onclick="pauseAIResponse(this)" disabled>
                        <i class="bi bi-pause-circle"></i> Pause
                    </button>
                </div>
            </div>
        `;

        voiceMessages.appendChild(messageDiv);
        scrollToBottom();

        try {
            // Simulate AI response (in real implementation, this would call OpenAI API)
            const aiResponse = "Thank you for sharing that experience. It demonstrates your problem-solving skills well. Now, let me ask you another question: How do you handle working under pressure and tight deadlines?";

            // Update the message with the real response
            messageDiv.innerHTML = `
                <div class="voice-avatar">
                    <i class="bi bi-robot"></i>
                </div>
                <div class="voice-content">
                    <div class="voice-header">
                        <span class="voice-sender">AI</span>
                        <span class="voice-time">${timeString}</span>
                    </div>
                    <div class="voice-text">${aiResponse}</div>
                    <div class="voice-controls">
                        <button class="btn btn-sm btn-outline-primary" onclick="playAIResponse(this)">
                            <i class="bi bi-play-circle"></i> Play
                        </button>
                        <button class="btn btn-sm btn-outline-secondary" onclick="pauseAIResponse(this)">
                            <i class="bi bi-pause-circle"></i> Pause
                        </button>
                    </div>
                </div>
            `;

            // Generate speech using browser's built-in speech synthesis
            setTimeout(() => {
                playAIVoiceResponse(aiResponse);
            }, 500);

        } catch (error) {
            console.error('Error getting AI response:', error);
            // Show error message
            messageDiv.innerHTML = `
                <div class="voice-avatar">
                    <i class="bi bi-robot"></i>
                </div>
                <div class="voice-content">
                    <div class="voice-header">
                        <span class="voice-sender">AI</span>
                        <span class="voice-time">${timeString}</span>
                    </div>
                    <div class="voice-text">I apologize, but I'm experiencing technical difficulties. Please try again.</div>
                </div>
            `;
        }
    }

    function playAIVoiceResponse(text) {
        // Use the browser's built-in speech synthesis
        if ('speechSynthesis' in window) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 0.9;
            utterance.pitch = 1;
            utterance.volume = 0.8;

            // Get available voices and set a good one
            const voices = speechSynthesis.getVoices();
            const preferredVoice = voices.find(voice =>
                voice.lang.includes('en') && voice.name.includes('Google')
            ) || voices.find(voice => voice.lang.includes('en'));

            if (preferredVoice) {
                utterance.voice = preferredVoice;
            }

            speechSynthesis.speak(utterance);
        }
    }

    function playAIResponse(button) {
        // Play the AI response using text-to-speech
        const messageContent = button.closest('.voice-content');
        const text = messageContent.querySelector('.voice-text').textContent;
        playAIVoiceResponse(text);
    }

    function pauseAIResponse(button) {
        // Pause the AI response audio
        if ('speechSynthesis' in window) {
            speechSynthesis.pause();
        }
    }

    function clearTranscription() {
        document.getElementById('transcriptionArea').value = '';
        document.getElementById('sendVoiceBtn').disabled = true;
    }

    function scrollToBottom() {
        const chatContainer = document.querySelector('.voice-chat-container');
        chatContainer.scrollTop = chatContainer.scrollHeight;
    }

    function finishInterview() {
        if (confirm('Are you sure you want to finish this interview? This action cannot be undone.')) {
            // In real implementation, this would mark the interview as finished in database
            alert('Interview finished! Redirecting to dashboard...');
            window.location.href = '/Dashboard';
        }
    }
</script>

@section Scripts {
    <partial name="_ValidationScriptsPartial" />
}
